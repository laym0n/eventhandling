# Requirements
- Сохранение события для обработки **MUST**
    - Возможность с каждым событием сохранять кастомную полезную нагрузку для обработки события (Payload) **MUST**
    - Наличие у каждого события названия **MUST**
    - API для сохранения события **MUST**
- Обработка сохраненных событий **MUST**
    - API для реализации обработчиков событий по названиям событий **MUST**
    - Гарантия at least once обработки события **MUST**
    - Конфигурация количества ретраев на случай неуспеха обработки событий **SHOULD**
    - Конфигурация количества ретраев на случай неуспеха обработки отдельных событий по их названиям **WON'T**
    - Сохранение неудачно обработанных событий для последующих разборов **SHOULD**
    - Мониторинг необработанных событий (логирование, Тенгри и Рефлекс) **SHOULD**
    - Partial order (Последовательность обработки событий в рамках одного groupId, например идентифкатор заявки) **COULD**
    - Обработка по приоритетам, а не по FIFO **WON'T**
    - Конфигурация обработки событий в несколько потоков **SHOULD**
    - Гарантированность нестухания в очереди (сообщение, добавленное в очередь успеет начать обрабатываться до того как наступит expired_at) **SHOULD**
- Очистка обработанных сообщений **MUST**
- Очистка старых необработанных сообщений **SHOULD**

#### MoSCoW

- MUST - требования обязательные для успеха
- SHOULD - важные, но необязательные требования
- COULD - требования, которые оказывают минимальное влияение и неплохо было бы их реализовать в последнюю очередь 
- WON'T - требования, которые не признаны приоритетными и не будут реализованы в ближайший релиз

# System Design

## Обработка событий

### Cинхронная обработка одним инстансом приложения - альтернатива 1
![Cинхронная обработка одним инстансом приложения](./out/one_instance_processing/one_instance_processing.png)

#### Плюсы:
- Простая быстрая и классическая реализация
- Гарантирует at least once обработку
#### Минусы:
- Невозможность использовать ресурсы всех приложений (1 инстанс обрабатывает)
- Остается шанс, что все потоки, выделенные под обработку событий забьются (выделили 10 потоков, прочитали 10 событий на обработку, все 10 событий оказались долгими запросами, например интеграция с Гигачат -> пока эти 10 операция не исполнятся осталные события не будут обрабатываться -> сообщение может стухнуть в очереди)

### Ассинхронная обработка всеми инстансами приложения - альтернатива 2
![Ассинхронная обработка всеми инстансами приложения](./out/multi_instance_processing/multi_instance_processing.png)

#### Плюсы:
- Гарантирует at least once обработку
- Возможность использовать ресурсы всех приложений
- Эффективное использование потоков за счет ассинхронной обработки (пока ассинхронно ожидаются ответы на 10 запросов, выделенные потоки могут обрабатывать другие запросы)

#### Минусы:
- Необходимость механизма блокировки событий, чтобы другие инстансы не брали одного и тоже событие в обработку
- Необходимость механизма разблокировки (1 инстанс приложения мог заблокировать событие, но не разблокировать, например из-за падения -> нужен механизм разблокировки событий, например по времени последнему взятию в работу)
- Дольшая разработка в сравнении с 1 альтернативой

### Синхронная обработка всеми инстансами приложения - альтернатива 3
Не имеет смысла, так как **не решается проблема долгой обработки событий** (просто становится больше ресурсов для обработки), все равно **требуется механизм блокировки**, чтобы разные инстансы приложения не брали одного и то же событие в обработку
**Больше имеет смысл альтернатива** - Ассинхронная обработка всеми инстансами приложения

### Ассинхронная обработка одним инстансом приложения - альтернатива 4
Не имеет смысла, так как все равно **требуется механизм блокировки** (так как работа шедулера может начаться раньше окончания обработки старых событий -> могут взяться старые события в обработку)
**Больше имеет смысл альтернатива** - Ассинхронная обработка всеми инстансами приложения

### Мой вывод
В первой итерации имеет смысл сделать `Cинхронная обработка одним инстансом приложения`, затем в случае наличия проблемы забивания потоков доработать до `Ассинхронная обработка всеми инстансами приложения`

## Успех обработки событий

### Удаление события сразу (Eager cleanup) - Альтернатива 1
![Удаление события сразу (Eager cleanup)](./out/one_instance_processing_eager_cleanup/one_instance_processing_eager_cleanup.png)

#### Плюсы:
- производительность поиска
- минимальный размер таблицы

#### Минусы:
- производительность удаления
- отсутствие аудита

### Удаление по шедулеру - Альтернатива 2
![Удаление по шедулеру](./out/one_instance_processing_schedule_cleanup/one_instance_processing_schedule_cleanup.png)

#### Плюсы:
- полный аудит
- настройка разных TTL для разных типов событий
- возможность восстановить события
- производительнее удаление
- статистика по обработанным событиями

#### Минусы:
- необходимость большего места
- ещё один шедулер
- производительность поиска (можно пофиксить таблицей success_event)

### Мой вывод
Использовать `Удаление события сразу`, по необходимости доработать до `Удаление по шедулеру`

## Неуспех обработки событий

### Сохранение в той же таблице - альтернатива 1

### Сохранение в таблице dead_events - альтернатива 2

## Выбор Сурена
- Удаление события сразу (Eager cleanup)
- Синхронная обработка
- Сохранение в той же таблице

![Итоговая обработка](./out/result_processing/processing.png)

## Логическая модель event
|Поле       |Тип                               |Описание|
|-----------|----------------------------------|--------|
|id         |UUID, PK                          ||
|create_date|TIMESTAMP WITH TIME ZONE, NOT NULL||
|name       |VARCHAR(100), NOT NULL            |название события|
|payload    |TEXT                              |payload для обработки|
|group_id   |VARCHAR(100)                      |идентификатор группы в рамках, которого необходимо обрабатывать события последовательно|
|retry      |SMALLINT, NOT NULL                |количество неудачных попыток обработки|
|max_retry  |SMALLINT, NOT NULL                |максимальное количество неудачных попыток обработки|

## Обработка
1. Поиск событий для обработки
```sql
SELECT *
FROM outbox_events
WHERE retry < max_retry
ORDER BY create_date
LIMIT :batch_size;
```

2. Сгруппировать события по `group_id` и каждую группу отсортировать по `create_date `
3. Для каждого события:
    1. Найти обработчик по `name`
    2. Передать на обработку событие
    3. Синхронно дождаться завершения обработки события
    4. Удалить событие по `id`
4. Если обработчик по `name` не найден
    1. установить `retry` равным `max_retry`
    2. Логирование, мониторинг
5. Если обработка события закончилась ошибкой
    1. увеличить `retry` на 1
    2. Логирование, мониторинг (как финальных, так и нет попыток обработки)

## Очистка
1. Запрос для очистки старых записей
```sql
DELETE *
FROM outbox_events
WHERE retry >= max_retry and create_date <= :cleanup_before_date
```

## Обработка b3 события issuings-ai-checks
1. Отфильтровать b3 сообщение
2. Сохранить событие c payload `{"triggerId":"triggerId", "applicationId":"applicationId"}`

## Обработка события из таблицы event issuings-ai-checks
1. Проверка просроченности задачи
2. Подсчитать количество записей в таблице `issuing_check` с значением поля `work_statusom` равным `NEW`
3. Если количество >= 2
    1. Сохранить новое событие c payload `{"triggerId":"triggerId", "applicationId":"applicationId"}`
    2. Закончить обработку
4. Обычная обработка